meta data:
{   'ann_output_processor': BatchProcessor([('sgmd', slice(0, 201, None), BatchProcessor([]))]),
    'dt': 900,
    'input_processor': BatchProcessor([('nmlz', slice(0, 1, None), BatchProcessor([]), tensor([0.]), tensor([48600000.])), ('1', slice(1, 3, None), BatchProcessor([]))]),
    'model': BESS(state=[14972849.        0.        1.], capacity=48600000.0, charging_efficiency=0.95, discharging_efficiency=0.95, relative_loss=0, correct_infeasible=True),
    'output_action_feasibility': True,
    'output_interaction': False,
    'output_new_state': False,
    'output_processor': None,
    'sampling_parameters': {   'infeasible_chance': 0.6666666666666666,
                               'soc_distribution': (   [   (0, 0.25),
                                                           (0.25, 0.75),
                                                           (0.75, 1)],
                                                       [0.375, 0.25, 0.375])}}
---
parameters:
{   'batch_count': 1000.0,
    'batch_norms': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
    'batch_size': 3072,
    'betas': array([0.5, 0.5, 2. , 0.5, 1. , 0.5, 1. , 2. , 1. , 1. ]),
    'dropout': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
    'early_stopping_callback': EarlyStoppingCallback(stopping_scores={}, improvement_window=100),
    'epoch_count': 1000,
    'hidden_layer_count': 5,
    'input_width': 3,
    'learning_rate': 0.005,
    'loss': MixedLoss([(BCEWithLogitsLoss(), 201)],tensor([1.], device='cuda:0'),cuda),
    'lr_scheduler': array([<class 'torch.optim.lr_scheduler.StepLR'>, {'step_size': 1, 'gamma': 0.99}], dtype=object),
    'max_grad_norm': 1000000.0,
    'output_activation': None,
    'output_width': 201,
    'regularization': L1RegularizationLoss(device=cuda, scale=2.000000E-09),
    'skips': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
       [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),
    'width': 32,
    'width_interpolation_steps_input': 0,
    'width_interpolation_steps_output': 0}
---
neural network:
Sequential(
  (0_linear(3,32)): Linear(in_features=3, out_features=32, bias=True)
  (0_swish(0'50)): Swish(
    (sigmoid): Sigmoid()
  )
  (1_linear(32,32)): Linear(in_features=32, out_features=32, bias=True)
  (1_swish(1'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (2_linear(32,32)): Linear(in_features=32, out_features=32, bias=True)
  (2_swish(2'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (3_linear(32,32)): Linear(in_features=32, out_features=32, bias=True)
  (3_swish(1'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (4_linear(32,32)): Linear(in_features=32, out_features=32, bias=True)
  (4_swish(1'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (5_linear(32,201)): Linear(in_features=32, out_features=201, bias=True)
)
---
parameter count:
10990
---
