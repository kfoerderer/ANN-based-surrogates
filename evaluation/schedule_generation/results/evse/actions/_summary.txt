meta data:
{   'ann_output_processor': BatchProcessor([('sgmd', slice(0, 101, None), BatchProcessor([]))]),
    'dt': 900,
    'input_processor': BatchProcessor([('nmlz', slice(0, 1, None), BatchProcessor([]), tensor([0.]), tensor([3.6000e+08])), ('1', slice(1, 4, None), BatchProcessor([])), ('oneh', slice(4, 5, None), BatchProcessor([]), tensor([    0.,   900.,  1800.,  2700.,  3600.,  4500.,  5400.,  6300.,  7200.,
         8100.,  9000.,  9900., 10800., 11700., 12600., 13500., 14400., 15300.,
        16200., 17100., 18000., 18900., 19800., 20700., 21600., 22500., 23400.,
        24300., 25200., 26100., 27000., 27900., 28800., 29700., 30600., 31500.,
        32400., 33300., 34200., 35100., 36000., 36900., 37800., 38700., 39600.,
        40500., 41400., 42300., 43200., 44100., 45000., 45900., 46800., 47700.,
        48600., 49500., 50400., 51300., 52200., 53100., 54000., 54900., 55800.,
        56700., 57600., 58500., 59400., 60300., 61200., 62100., 63000., 63900.,
        64800., 65700., 66600., 67500., 68400., 69300., 70200., 71100., 72000.,
        72900., 73800., 74700., 75600., 76500., 77400., 78300., 79200., 80100.,
        81000., 81900., 82800., 83700., 84600., 85500., 86400.]))]),
    'model': EVSE(state=[3.600000e+08 6.206943e-01 9.978993e-01 4.575619e-01 8.010000e+04], charging_efficiency=360000000.0, correct_infeasible=1, constraint_fuzziness=True),
    'output_action_feasibility': True,
    'output_interaction': False,
    'output_new_state': False,
    'output_processor': None,
    'sampling_parameters': {'infeasible_chance': 0.6666666666666666}}
---
parameters:
{   'batch_count': 1000.0,
    'batch_norms': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
    'batch_size': 3072,
    'betas': array([1. , 0.5, 0.5, 1. , 1. , 2. , 1. , 2. , 0.5, 2. ]),
    'dropout': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
    'early_stopping_callback': EarlyStoppingCallback(stopping_scores={}, improvement_window=100),
    'epoch_count': 1000,
    'hidden_layer_count': 6,
    'input_width': 101,
    'learning_rate': 0.005,
    'loss': MixedLoss([(BCEWithLogitsLoss(), 101)],tensor([1.], device='cuda:0'),cuda),
    'lr_scheduler': array([<class 'torch.optim.lr_scheduler.StepLR'>, {'step_size': 25, 'gamma': 0.75}], dtype=object),
    'max_grad_norm': 1000000.0,
    'output_activation': None,
    'output_width': 101,
    'regularization': L1RegularizationLoss(device=cuda, scale=2.000000E-08),
    'skips': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]),
    'width': 32,
    'width_interpolation_steps_input': 0,
    'width_interpolation_steps_output': 4}
---
neural network:
Sequential(
  (0_linear(101,32)): Linear(in_features=101, out_features=32, bias=True)
  (0_swish(1'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (1_linear(32,32)): Linear(in_features=32, out_features=32, bias=True)
  (1_swish(2'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (2_linear(32,46)): Linear(in_features=32, out_features=46, bias=True)
  (2_swish(1'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (3_linear(46,60)): Linear(in_features=46, out_features=60, bias=True)
  (3_swish(2'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (4_linear(60,74)): Linear(in_features=60, out_features=74, bias=True)
  (4_swish(0'50)): Swish(
    (sigmoid): Sigmoid()
  )
  (5_linear(74,88)): Linear(in_features=74, out_features=88, bias=True)
  (5_swish(2'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (6_linear(88,101)): Linear(in_features=88, out_features=101, bias=True)
)
---
parameter count:
28767
---
