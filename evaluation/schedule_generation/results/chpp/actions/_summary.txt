meta data:
{   'ann_output_processor': BatchProcessor([('sgmd', slice(0, 101, None), BatchProcessor([]))]),
    'dt': 900,
    'input_processor': BatchProcessor([('disc', slice(0, 1, None), BatchProcessor([]), tensor([0.])), ('oneh', slice(1, 2, None), BatchProcessor([]), tensor([0., 1.])), ('oneh', slice(2, 3, None), BatchProcessor([]), tensor([ 900., 1800., 2700., 3600., 4500., 5400., 6300., 7200.])), ('oneh', slice(3, 4, None), BatchProcessor([]), tensor([ 900., 1800., 2700., 3600., 4500., 5400., 6300., 7200.])), ('oneh', slice(4, 5, None), BatchProcessor([]), tensor([ 900., 1800., 2700., 3600., 4500., 5400., 6300., 7200.])), ('nmlz', slice(5, 7, None), BatchProcessor([]), tensor([60., 20.]), tensor([20.,  1.]))]),
    'model': CHPP_HWT(CHPP(state=[   0 7200 6300 2700], state_matrix=[[(0.0, 0), (-2750.0, -6250.0)], [(-2750.0, -6250.0), (-5500.0, -12500)]], correct_infeasible=True),HWT(state=[71.641722 20.      ], soft_mix_temp=60.0, soft_max_temp=80.0, volume=0.75, charging_efficiency=1, discharging_efficiency=1, relative_loss=0.0024453491692814603, max_temp=90),demand(state=[0.], hidden_state=[62 420 array([], shape=(0, 1), dtype=float64)]),constraint_fuzziness=0.01),
    'output_action_feasibility': True,
    'output_interaction': False,
    'output_new_state': False,
    'output_processor': None,
    'sampling_parameters': {   'dwell_times': [   900,
                                                  1800,
                                                  2700,
                                                  3600,
                                                  4500,
                                                  5400,
                                                  6300,
                                                  7200],
                               'infeasible_chance': 0.5,
                               'min_off_times': [   900,
                                                    1800,
                                                    2700,
                                                    3600,
                                                    4500,
                                                    5400,
                                                    6300,
                                                    7200],
                               'min_on_times': [   900,
                                                   1800,
                                                   2700,
                                                   3600,
                                                   4500,
                                                   5400,
                                                   6300,
                                                   7200],
                               'temp_distribution': (   [   (20, 58),
                                                            (58, 62),
                                                            (62, 78),
                                                            (78, 82),
                                                            (82, 90)],
                                                        [   0.1,
                                                            0.15,
                                                            0.5,
                                                            0.15,
                                                            0.1])}}
---
parameters:
{   'batch_count': 1000.0,
    'batch_norms': array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),
    'batch_size': 3072,
    'betas': array([1. , 0.5, 2. , 0.5, 2. , 2. , 1. , 1. , 2. , 0.5]),
    'dropout': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
    'early_stopping_callback': EarlyStoppingCallback(stopping_scores={}, improvement_window=100),
    'epoch_count': 1000,
    'hidden_layer_count': 8,
    'input_width': 29,
    'learning_rate': 0.005,
    'loss': MixedLoss([(BCEWithLogitsLoss(), 101)],tensor([1.], device='cuda:0'),cuda),
    'lr_scheduler': array([<class 'torch.optim.lr_scheduler.StepLR'>, {'step_size': 1, 'gamma': 0.99}], dtype=object),
    'max_grad_norm': 1000000.0,
    'output_activation': None,
    'output_width': 101,
    'regularization': L1RegularizationLoss(device=cuda, scale=2.000000E-09),
    'skips': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]),
    'width': 256,
    'width_interpolation_steps_input': 0,
    'width_interpolation_steps_output': 4}
---
neural network:
Sequential(
  (0_linear(29,256)): Linear(in_features=29, out_features=256, bias=True)
  (0_swish(2'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (1_linear(256,256)): Linear(in_features=256, out_features=256, bias=True)
  (1_swish(0'50)): Swish(
    (sigmoid): Sigmoid()
  )
  (2_linear(256,256)): Linear(in_features=256, out_features=256, bias=True)
  (2_swish(2'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (3_linear(256,256)): Linear(in_features=256, out_features=256, bias=True)
  (3_swish(2'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (4_linear(256,225)): Linear(in_features=256, out_features=225, bias=True)
  (4_swish(1'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (5_linear(225,194)): Linear(in_features=225, out_features=194, bias=True)
  (5_swish(1'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (6_linear(194,163)): Linear(in_features=194, out_features=163, bias=True)
  (6_swish(2'00)): Swish(
    (sigmoid): Sigmoid()
  )
  (7_linear(163,132)): Linear(in_features=163, out_features=132, bias=True)
  (7_swish(0'50)): Swish(
    (sigmoid): Sigmoid()
  )
  (8_batch_norm(132)): BatchNorm1d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (8_linear(132,101)): Linear(in_features=132, out_features=101, bias=True)
)
---
parameter count:
373863
---
